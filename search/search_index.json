{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Django tasks Scheduler","text":"<p>A database backed asynchronous tasks scheduler for django. This allows remembering scheduled tasks, their parameters, etc.</p> <p>Important</p> <p>Version 3.0.0 introduced a major design change. Instead of three separate models, there is one new <code>Task</code> model. The goal is to simplify. Make sure to follow the migration guide</p>"},{"location":"#architecture-and-terminology","title":"Architecture and terminology","text":"<pre><code>flowchart TD\n    subgraph Django Process\n        task[Scheduled Task&lt;br/&gt; django-model]\n    end\n    db[(Relational&lt;br/&gt;Database)]\n    subgraph Worker\n        worker[Worker&lt;br/&gt;Queue listener&lt;br/&gt;Job Execution]\n        commands[Worker&lt;br/&gt;commands&lt;br/&gt;Listener]\n        scheduler[Scheduler]\n        scheduler ~~~ commands ~~~ worker\n    end\n\n    subgraph Broker\n        job[Job]\n        commandsChannel[Workers&lt;br/&gt;Commands&lt;br/&gt;Channel]\n        subgraph Queue\n            direction TB\n            scheduled[Scheduled Jobs]\n            queued[Queued jobs]\n            active[Active jobs]\n            finished[Finished jobs]\n            failed[Failed jobs]\n            canceled[Canceled jobs]\n            scheduled ~~~ queued ~~~ active\n            active ~~~ finished\n            active ~~~ failed\n            queued ~~~ canceled\n        end\n        job ~~~ commandsChannel\n    end\n\n    task --&gt; db\n    task --&gt;|Create instance of executing a task| job\n    job --&gt;|Queuing a job to be executed| scheduled\n    scheduled -.-&gt;|Queue jobs| scheduler -.-&gt; queued\n    queued -.-&gt;|Worker picking up job to execute| worker\n    worker -.-&gt;|Moves it to active jobs| active\n    active -.-&gt;|Once terminated successfully| finished\n    active -.-&gt;|Once terminated unsuccessfully or stopped| failed\n    queued -...-&gt;|In case job is stopped before starting| canceled</code></pre>"},{"location":"#scheduled-task","title":"Scheduled Task","text":"<p>django-tasks-scheduler is using a single <code>Task</code> django-model with different task types, the task types are:</p> <ul> <li><code>ONCE</code> - Run the task once at a scheduled time.</li> <li><code>REPEATABLE</code> - Run the task multiple times (limited number of times or infinite times) based on a time interval.</li> <li><code>CRON</code> - Run a task indefinitely based on a cron string schedule.</li> </ul> <p>This enables having one admin view for all scheduled tasks, and having one table in the database to maintain the task reduces the number of overall queries. An <code>Task</code> instance contains all relevant information about a task to enable the users to schedule using django-admin and track their status.</p>"},{"location":"#job","title":"Job","text":"<p>A job is a record in the broker, containing all information required to execute a piece of code, usually representing a task, but not necessarily.</p> <p>It contains the following information:</p> <ul> <li>Name of the job (that is unique, and passed in different queues).</li> <li>Link to the task.</li> <li>Reference to the method to be executed.</li> <li>Callbacks (In case of failure/success/stopped).</li> <li>Timeout details (for method to be executed, for callbacks)</li> <li>Successful/Failed result time-to-live.</li> </ul>"},{"location":"#queue","title":"Queue","text":"<p>A queue of messages between processes (main django-app process and worker usually). It is a collection of different registries for different purposes:</p> <ul> <li>Scheduled jobs: Jobs that are scheduled to run</li> <li>Queued jobs: Jobs waiting to be picked up by a worker to run.</li> <li>Active jobs: Jobs that are currently being executed.</li> <li>Finished jobs: Jobs that have been successfully executed</li> <li>Failed jobs: Jobs that have failed to execute or have been stopped</li> <li>Canceled jobs: Jobs that have been stopped/canceled before they were executed</li> </ul>"},{"location":"#worker","title":"Worker","text":"<p>A process listening to one or more queues for jobs to be executed, and executing jobs queued to be executed.</p> <ul> <li>A worker has a thread listening to a channel where it can get specific commands.</li> <li>A worker can have, by default, a subprocess for the scheduler.</li> </ul>"},{"location":"#scheduler-worker-sub-process","title":"Scheduler (Worker sub-process)","text":"<p>A process listening to one or more queues for jobs to be scheduled for execution, and schedule them to be executed by a worker (i.e., move them from scheduled-jobs registry to queued-jobs registry).</p> <p>This is a sub-process of worker.</p>"},{"location":"#job_1","title":"Job","text":"<p>Once a worker listening to the queue becomes available, the job will be executed.</p> <p>A scheduler checking the queue periodically will check whether the time the job should be executed has come, and if so, it will queue it, i.e., add it to the queued-jobs registry.</p> <ul> <li>A job is considered scheduled if it is queued to be executed, or scheduled to be executed.</li> <li>If there is no scheduler, the job will not be queued to run.</li> </ul>"},{"location":"#scheduler-sequence-diagram","title":"Scheduler sequence diagram","text":"<pre><code>sequenceDiagram\n    autonumber\n    box DB\n        participant db as Database\n    end\n    box Worker\n        participant scheduler as Scheduler Process\n    end\n    box Broker\n        participant job as Job\n    end\n    box Broker Queue\n        participant schedule as Scheduled jobs\n        participant queue as Queued jobs\n    end\n    loop Scheduler process - loop forever\n        note over db, schedule: Database interaction\n        scheduler -&gt;&gt; db: Check for enabled tasks that should be scheduled\n        critical There are tasks to be scheduled\n            scheduler -&gt;&gt; job: Create job for task that should be scheduled\n            scheduler -&gt;&gt; schedule: Add the job to the scheduled-jobs registry\n        end\n        note over scheduler, queue: Broker queues interaction\n        scheduler -&gt;&gt; schedule: check whether there are scheduled tasks that should be executed\n        critical there are jobs that are scheduled to be executed\n            scheduler -&gt;&gt; schedule: remove jobs to be scheduled\n            scheduler -&gt;&gt; queue: enqueue jobs to be executed\n        end\n        scheduler -&gt;&gt; scheduler: sleep interval (See SCHEDULER_INTERVAL)\n    end</code></pre>"},{"location":"#worker-sequence-diagram","title":"Worker sequence diagram","text":"<pre><code>sequenceDiagram\n    autonumber\n    box Worker\n        participant worker as Worker Process\n    end\n    box Queue\n        participant queue as Queued jobs\n        participant finished as Finished jobs\n        participant failed as Failed jobs\n    end\n    box Broker\n        participant job as Job\n        participant result as Result\n    end\n    loop Worker process - loop forever\n        worker -&gt;&gt;+ queue: get the first job to be executed\n        queue --&gt;&gt;- worker: A job to be executed or nothing\n        critical There is a job to be executed\n            note over worker, result: There is a job to be executed\n            worker -&gt;&gt; queue: Remove job from queued registry\n            worker -&gt;&gt; worker: Execute job\n            critical Job ended successfully\n                worker -&gt;&gt; worker: Execute successful callbacks\n                worker -&gt;&gt; finished: Move job to finished-jobs registry\n                worker -&gt;&gt; job: Update job details\n                worker -&gt;&gt; result: Write result\n            option Job ended unsuccessfully\n                worker -&gt;&gt; worker: Execute failure callbacks\n                worker -&gt;&gt; failed: Move job to failed-jobs registry\n                worker -&gt;&gt; job: Update job details\n                worker -&gt;&gt; result: Write result\n            end\n        option No job to be executed\n            note over worker, result: No job to be executed\n            worker -&gt;&gt; worker: sleep\n        end\n    end</code></pre>"},{"location":"#reporting-issues-or-features-requests","title":"Reporting issues or Features requests","text":"<p>Please report issues via GitHub Issues .</p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<ul> <li>Some django-admin views and their tests were adopted from django-rq.</li> <li>Worker and Queue implementation was inspired by rq.</li> </ul>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v403","title":"v4.0.3 \ud83c\udf08","text":""},{"location":"changelog/#bug-fixes","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Updated <code>scheduler_worker</code> management command argument to <code>--without-scheduler</code> since the worker has a scheduler by   default.</li> </ul>"},{"location":"changelog/#v402","title":"v4.0.2 \ud83c\udf08","text":""},{"location":"changelog/#bug-fixes_1","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Add type hint for <code>JOB_METHODS_LIST</code></li> <li>Fix issue creating new <code>ONCE</code> task without a scheduled time #270</li> </ul>"},{"location":"changelog/#maintenance","title":"\ud83e\uddf0 Maintenance","text":"<ul> <li>Update dependencies to latest versions</li> <li>Migrate to use <code>uv</code> instead of <code>poetry</code> for package management</li> </ul>"},{"location":"changelog/#v400","title":"v4.0.0 \ud83c\udf08","text":"<p>See breaking changes in 4.0.0 beta versions.</p>"},{"location":"changelog/#bug-fixes_2","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Fix issue with non-primitive parameters for @job #249</li> </ul>"},{"location":"changelog/#v400b3","title":"v4.0.0b3 \ud83c\udf08","text":"<p>Refactor the code to make it more organized and easier to maintain. This includes:</p> <ul> <li>All types are under <code>types</code> instead of separated to <code>broker_types</code> and <code>settings_types</code>.</li> <li>Added <code>__all__</code> to <code>models</code>, and other packages.</li> </ul>"},{"location":"changelog/#v400b2","title":"v4.0.0b2 \ud83c\udf08","text":""},{"location":"changelog/#bug-fixes_3","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Fix bug when <code>SCHEDULER_CONFIG</code> is <code>SchedulerConfiguration</code></li> </ul>"},{"location":"changelog/#v400b1","title":"v4.0.0b1 \ud83c\udf08","text":""},{"location":"changelog/#breaking-changes","title":"Breaking Changes","text":"<p>This version is a full revamp of the package. The main changes are related to removing the RQ dependency. Worker/Queue/Job are all implemented in the package itself. This change allows for more flexibility and control over the tasks.</p> <p>Management commands:</p> <ul> <li><code>rqstats</code> =&gt; <code>scheduler_stats</code></li> <li><code>rqworker</code> =&gt; <code>scheduler_worker</code></li> </ul> <p>Settings:</p> <ul> <li><code>SCHEDULER_CONFIG</code> is now a <code>SchedulerConfiguration</code> object to help IDE guide settings.</li> <li><code>SCHEDULER_QUEUES</code> is now a list of <code>QueueConfiguration</code> objects to help IDE guide settings.</li> <li>Configuring queue to use <code>SSL</code>/<code>SSL_CERT_REQS</code>/<code>SOCKET_TIMEOUT</code> is now done using <code>CONNECTION_KWARGS</code> in   <code>QueueConfiguration</code> <code>python   SCHEDULER_QUEUES: Dict[str, QueueConfiguration] = {     'default': QueueConfiguration(         HOST='localhost',         PORT=6379,         USERNAME='some-user',         PASSWORD='some-password',         CONNECTION_KWARGS={  # Eventual additional Broker connection arguments             'ssl_cert_reqs': 'required',             'ssl':True,         },     ),    # ...    }</code></li> <li>For how to configure in <code>settings.py</code>, please see the settings documentation.</li> </ul>"},{"location":"changelog/#v302","title":"v3.0.2 \ud83c\udf08","text":""},{"location":"changelog/#bug-fixes_4","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Fix issue updating wrong field #233</li> </ul>"},{"location":"changelog/#v301","title":"v3.0.1 \ud83c\udf08","text":""},{"location":"changelog/#bug-fixes_5","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Lookup error issue #228.</li> </ul>"},{"location":"changelog/#maintenance_1","title":"\ud83e\uddf0 Maintenance","text":"<ul> <li>Migrated to use ruff instead of flake8/black</li> </ul>"},{"location":"changelog/#v300","title":"v3.0.0 \ud83c\udf08","text":""},{"location":"changelog/#breaking-changes_1","title":"Breaking Changes","text":"<ul> <li>Renamed <code>REDIS_CLIENT_KWARGS</code> configuration to <code>CLIENT_KWARGS</code>.</li> </ul>"},{"location":"changelog/#features","title":"\ud83d\ude80 Features","text":"<ul> <li>Created a new <code>Task</code> model representing all kind of scheduled tasks.<ul> <li>In future versions, <code>CronTask</code>, <code>ScheduledTask</code> and <code>RepeatableTask</code> will be removed.</li> <li><code>Task</code> model has a <code>task_type</code> field to differentiate between the types of tasks.</li> <li>Old tasks in the database will be migrated to the new <code>Task</code> model automatically.</li> </ul> </li> </ul>"},{"location":"changelog/#maintenance_2","title":"\ud83e\uddf0 Maintenance","text":"<ul> <li>Update dependencies to latest versions.</li> </ul>"},{"location":"changelog/#v211","title":"v2.1.1 \ud83c\udf08","text":""},{"location":"changelog/#bug-fixes_6","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Support for valkey sentinel configuration @amirreza8002 (#191)</li> <li>Fix issue with task being scheduled despite being already scheduled #202</li> </ul>"},{"location":"changelog/#v210","title":"v2.1.0 \ud83c\udf08","text":""},{"location":"changelog/#features_1","title":"\ud83d\ude80 Features","text":"<ul> <li>Support for custom job-class for every worker, using <code>--job-class</code> option in <code>rqworker</code> command. @gabriels1234 (#160)</li> <li>Support for integrating with sentry, using <code>--sentry-dsn</code>, <code>--sentry-debug</code>, and <code>--sentry-ca-certs</code> options in   <code>rqworker</code> command.</li> <li>Support for using ValKey as broker instead of redis.</li> </ul>"},{"location":"changelog/#maintenance_3","title":"\ud83e\uddf0 Maintenance","text":"<ul> <li>Refactor settings module.</li> </ul>"},{"location":"changelog/#v200","title":"v2.0.0 \ud83c\udf08","text":""},{"location":"changelog/#breaking-changes_2","title":"Breaking Changes","text":"<ul> <li>Remove support for django 3.* and 4.*. Only support django 5.0 and above.</li> </ul>"},{"location":"changelog/#v134","title":"v1.3.4 \ud83c\udf08","text":""},{"location":"changelog/#maintenance_4","title":"\ud83e\uddf0 Maintenance","text":"<ul> <li>Update dependencies to latest versions</li> </ul>"},{"location":"changelog/#v133","title":"v1.3.3 \ud83c\udf08","text":""},{"location":"changelog/#bug-fixes_7","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Fix issue of django generating a new migration when settings.SCHEDULER_QUEUES is changed #119</li> </ul>"},{"location":"changelog/#v132","title":"v1.3.2 \ud83c\udf08","text":"<ul> <li>Fix issue with job_details template on python3.12 @cyber237 #87</li> </ul>"},{"location":"changelog/#v131","title":"v1.3.1 \ud83c\udf08","text":""},{"location":"changelog/#bug-fixes_8","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Fix workers' page when there are no queues #83</li> </ul>"},{"location":"changelog/#maintenance_5","title":"\ud83e\uddf0 Maintenance","text":"<ul> <li>Removes psycopg2 dependency from pyproject.toml @mbi (#78)</li> </ul>"},{"location":"changelog/#v130","title":"v1.3.0 \ud83c\udf08","text":""},{"location":"changelog/#features_2","title":"\ud83d\ude80 Features","text":"<ul> <li>Add to CronTask and RepeatableTask counters for successful/failed runs.</li> </ul>"},{"location":"changelog/#maintenance_6","title":"\ud83e\uddf0 Maintenance","text":"<ul> <li>Support for django 5.0</li> <li>Update homepage url @dirkmueller (#65)</li> </ul>"},{"location":"changelog/#v124","title":"v1.2.4 \ud83c\udf08","text":""},{"location":"changelog/#bug-fixes_9","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Fix for non-existent task @gabriels1234 (#62)</li> </ul>"},{"location":"changelog/#maintenance_7","title":"\ud83e\uddf0 Maintenance","text":"<ul> <li>Use rq <code>fetch_many</code></li> </ul>"},{"location":"changelog/#v123","title":"v1.2.3 \ud83c\udf08","text":""},{"location":"changelog/#bug-fixes_10","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Fix When a job fails it becomes unscheduled #45</li> </ul>"},{"location":"changelog/#v121","title":"v1.2.1 \ud83c\udf08","text":""},{"location":"changelog/#bug-fixes_11","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Fix infinite loop on callback calling is_scheduled() #37.</li> </ul>"},{"location":"changelog/#v120","title":"v1.2.0 \ud83c\udf08","text":""},{"location":"changelog/#features_3","title":"\ud83d\ude80 Features","text":"<ul> <li>Rename <code>*Job</code> models to <code>*Task</code> to differentiate.</li> </ul>"},{"location":"changelog/#v110","title":"v1.1.0 \ud83c\udf08","text":""},{"location":"changelog/#features_4","title":"\ud83d\ude80 Features","text":"<ul> <li>Enable using stats view using api token</li> <li>Reverted, active jobs are not marked as scheduled as there is currently no new job instance for them.</li> </ul>"},{"location":"changelog/#bug-fixes_12","title":"\ud83d\udc1b Bug Fixes","text":""},{"location":"changelog/#32-running-jobs-should-be-marked-as-scheduled-jobs-rstalbow-33","title":"32 Running jobs should be marked as scheduled jobs. @rstalbow (#33)","text":""},{"location":"changelog/#v102","title":"v1.0.2 \ud83c\udf08","text":""},{"location":"changelog/#maintenance_8","title":"\ud83e\uddf0 Maintenance","text":"<ul> <li>Update dependencies</li> </ul>"},{"location":"changelog/#bug-fixes_13","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Add missing migration and check for missing migrations</li> </ul>"},{"location":"changelog/#v101","title":"v1.0.1 \ud83c\udf08","text":"<ul> <li>Update dependencies</li> <li>Remove redundant log calls</li> </ul>"},{"location":"changelog/#v100","title":"v1.0.0 \ud83c\udf08","text":"<ul> <li>Migrated from django-rq-scheduler</li> </ul>"},{"location":"commands/","title":"Management commands","text":""},{"location":"commands/#scheduler_worker-create-a-worker","title":"<code>scheduler_worker</code> - Create a worker","text":"<p>Create a new worker with a scheduler for specific queues by order of priority. If no queues are specified, will run on default queue only.</p> <p>All queues must have the same redis settings on <code>SCHEDULER_QUEUES</code>.</p> <pre><code>usage: manage.py scheduler_worker [-h] [--pid PIDFILE] [--name NAME] [--worker-ttl WORKER_TTL]\n                                  [--fork-job-execution FORK_JOB_EXECUTION] [--sentry-dsn SENTRY_DSN] [--sentry-debug]\n                                  [--sentry-ca-certs SENTRY_CA_CERTS] [--burst] [--max-jobs MAX_JOBS]\n                                  [--max-idle-time MAX_IDLE_TIME] [--without-scheduler] [--version] [-v {0,1,2,3}]\n                                  [--settings SETTINGS] [--pythonpath PYTHONPATH] [--traceback] [--no-color] [--force-color]\n                                  [--skip-checks]\n                                  [queues ...]\n\npositional arguments:\n  queues                The queues to work on, separated by space, all queues should be using the same redis\n\noptions:\n  -h, --help            show this help message and exit\n  --pid PIDFILE         file to write the worker`s pid into\n  --name NAME           Name of the worker\n  --worker-ttl WORKER_TTL\n                        Default worker timeout to be used\n  --fork-job-execution FORK_JOB_EXECUTION\n                        Fork job execution to another process\n  --sentry-dsn SENTRY_DSN\n                        Sentry DSN to use\n  --sentry-debug        Enable Sentry debug mode\n  --sentry-ca-certs SENTRY_CA_CERTS\n                        Path to CA certs file\n  --burst               Run worker in burst mode\n  --max-jobs MAX_JOBS   Maximum number of jobs to execute before terminating worker\n  --max-idle-time MAX_IDLE_TIME\n                        Maximum number of seconds to wait for new job before terminating worker\n  --without-scheduler   Run worker without scheduler, default to with scheduler\n  --version             Show program's version number and exit.\n  -v, --verbosity {0,1,2,3}\n                        Verbosity level; 0=minimal output, 1=normal output, 2=verbose output, 3=very verbose output\n  --settings SETTINGS   The Python path to a settings module, e.g. \"myproject.settings.main\". If this isn't provided, the\n                        DJANGO_SETTINGS_MODULE environment variable will be used.\n  --pythonpath PYTHONPATH\n                        A directory to add to the Python path, e.g. \"/home/djangoprojects/myproject\".\n  --traceback           Display a full stack trace on CommandError exceptions.\n  --no-color            Don't colorize the command output.\n  --force-color         Force colorization of the command output.\n  --skip-checks         Skip system checks.\n</code></pre>"},{"location":"commands/#export-export-scheduled-tasks","title":"<code>export</code> - Export scheduled tasks","text":"<p>Export all scheduled tasks from django db to json/yaml format.</p> <pre><code>python manage.py export -o {yaml,json}\n</code></pre> <p>Result should be (for json):</p> <pre><code>[\n  {\n    \"model\": \"CronTaskType\",\n    \"name\": \"Scheduled Task 1\",\n    \"callable\": \"scheduler.tests.test_job\",\n    \"callable_args\": [\n      {\n        \"arg_type\": \"datetime\",\n        \"val\": \"2022-02-01\"\n      }\n    ],\n    \"callable_kwargs\": [],\n    \"enabled\": true,\n    \"queue\": \"default\",\n    \"at_front\": false,\n    \"timeout\": null,\n    \"result_ttl\": null,\n    \"scheduled_time\": \"2023-02-21T14:06:06\"\n  },\n  ...\n]\n</code></pre>"},{"location":"commands/#import-import-scheduled-tasks","title":"<code>import</code> - Import scheduled tasks","text":"<p>A json/yaml that was exported using the <code>export</code> command can be imported to django.</p> <ul> <li>Specify the source file using <code>--filename</code> or take it from the standard input (default).</li> <li>Reset all scheduled tasks in the database before importing using <code>-r</code>/<code>--reset</code>.</li> <li>Update existing jobs for names that are found using <code>-u</code>/<code>--update</code>.</li> </ul> <pre><code>python manage.py import -f {yaml,json} --filename {SOURCE-FILE}\n</code></pre>"},{"location":"commands/#run_job-run-a-job-immediately","title":"<code>run_job</code> - Run a job immediately","text":"<p>Run a method in a queue immediately.</p> <pre><code>python manage.py run_job {callable} {callable args ...}\n</code></pre>"},{"location":"commands/#delete_failed_jobs-delete-failed-jobs","title":"<code>delete_failed_jobs</code> - delete failed jobs","text":"<p>Run this to empty failed jobs registry from a queue.</p> <pre><code>python manage.py delete_failed_jobs \n</code></pre>"},{"location":"commands/#scheduler_stats-show-scheduler-stats","title":"<code>scheduler_stats</code> - Show scheduler stats","text":"<p>Prints scheduler stats as a table, json, or yaml, example:</p> <pre><code>$ python manage.py scheduler_stats\n\nDjango-Scheduler CLI Dashboard\n\n--------------------------------------------------------------------------------\n| Name             |    Queued |    Active |  Finished |  Canceled |   Workers |\n--------------------------------------------------------------------------------\n| default          |         0 |         0 |         0 |         0 |         0 |\n| low              |         0 |         0 |         0 |         0 |         0 |\n| high             |         0 |         0 |         0 |         0 |         0 |\n| medium           |         0 |         0 |         0 |         0 |         0 |\n| another          |         0 |         0 |         0 |         0 |         0 |\n--------------------------------------------------------------------------------\n</code></pre> <pre><code>usage: manage.py scheduler_stats [-h] [-j] [-y] [-i INTERVAL] [--version] [-v {0,1,2,3}] [--settings SETTINGS] [--pythonpath PYTHONPATH] [--traceback] [--no-color] [--force-color] [--skip-checks]\n\nPrint statistics\n\noptions:\n  -h, --help            show this help message and exit\n  -j, --json            Output statistics as JSON\n  -y, --yaml            Output statistics as YAML\n  -i INTERVAL, --interval INTERVAL\n                        Poll statistics every N seconds\n  --version             Show program's version number and exit.\n  -v {0,1,2,3}, --verbosity {0,1,2,3}\n                        Verbosity level; 0=minimal output, 1=normal output, 2=verbose output, 3=very verbose output\n  --settings SETTINGS   The Python path to a settings module, e.g. \"myproject.settings.main\". If this isn't provided, the DJANGO_SETTINGS_MODULE environment variable will be used.\n  --pythonpath PYTHONPATH\n                        A directory to add to the Python path, e.g. \"/home/djangoprojects/myproject\".\n  --traceback           Raise on CommandError exceptions.\n  --no-color            Don't colorize the command output.\n  --force-color         Force colorization of the command output.\n  --skip-checks         Skip system checks.\n</code></pre>"},{"location":"configuration/","title":"Configure your django-tasks-scheduler","text":""},{"location":"configuration/#settingspy","title":"settings.py","text":"<p>All default settings for scheduler can be in one dictionary in <code>settings.py</code>:</p> <pre><code>import os\nfrom typing import Dict\nfrom scheduler.types import SchedulerConfiguration, Broker, QueueConfiguration\n\nSCHEDULER_CONFIG = SchedulerConfiguration(\n    EXECUTIONS_IN_PAGE=20,\n    SCHEDULER_INTERVAL=10,\n    BROKER=Broker.REDIS,\n    CALLBACK_TIMEOUT=60,  # Callback timeout in seconds (success/failure/stopped)\n    # Default values, can be overriden per task/job\n    DEFAULT_SUCCESS_TTL=10 * 60,  # Time To Live (TTL) in seconds to keep successful job results\n    DEFAULT_FAILURE_TTL=365 * 24 * 60 * 60,  # Time To Live (TTL) in seconds to keep job failure information\n    DEFAULT_JOB_TTL=10 * 60,  # Time To Live (TTL) in seconds to keep job information\n    DEFAULT_JOB_TIMEOUT=5 * 60,  # timeout (seconds) for a job\n    # General configuration values\n    DEFAULT_WORKER_TTL=10 * 60,  # Time To Live (TTL) in seconds to keep worker information after last heartbeat\n    DEFAULT_MAINTENANCE_TASK_INTERVAL=10 * 60,  # The interval to run maintenance tasks in seconds. 10 minutes.\n    DEFAULT_JOB_MONITORING_INTERVAL=30,  # The interval to monitor jobs in seconds.\n    SCHEDULER_FALLBACK_PERIOD_SECS=120,  # Period (secs) to wait before requiring to reacquire locks\n)\nSCHEDULER_QUEUES: Dict[str, QueueConfiguration] = {\n    'default': QueueConfiguration(\n        HOST='localhost',\n        PORT=6379,\n        USERNAME='some-user',\n        PASSWORD='some-password',\n        CONNECTION_KWARGS={  # Eventual additional Broker connection arguments\n            'ssl_cert_reqs': 'required',\n            'ssl': True,\n        },\n    ),\n    'high': QueueConfiguration(URL=os.getenv('REDISTOGO_URL', 'redis://localhost:6379/0')),\n    'low': QueueConfiguration(HOST='localhost', PORT=6379, DB=0, ASYNC=False),\n}\n</code></pre>"},{"location":"configuration/#scheduler_config-executions_in_page","title":"SCHEDULER_CONFIG: <code>EXECUTIONS_IN_PAGE</code>","text":"<p>Number of job executions to show in a page in a ScheduledJob admin view.</p> <p>Default: <code>20</code>.</p>"},{"location":"configuration/#scheduler_config-scheduler_interval","title":"SCHEDULER_CONFIG: <code>SCHEDULER_INTERVAL</code>","text":"<p>Default scheduler interval, a scheduler is a subprocess of a worker and will check which job executions are pending.</p> <p>Default: <code>10</code> (10 seconds).</p>"},{"location":"configuration/#scheduler_config-broker","title":"SCHEDULER_CONFIG: <code>BROKER</code>","text":""},{"location":"configuration/#scheduler_config-callback_timeout","title":"SCHEDULER_CONFIG: <code>CALLBACK_TIMEOUT</code>","text":""},{"location":"configuration/#scheduler_config-default_success_ttl","title":"SCHEDULER_CONFIG: <code>DEFAULT_SUCCESS_TTL</code>","text":"<p>Default time to live for job execution result when it is successful.</p> <p>Default: <code>600</code> (10 minutes).</p>"},{"location":"configuration/#scheduler_config-default_failure_ttl","title":"SCHEDULER_CONFIG: <code>DEFAULT_FAILURE_TTL</code>","text":"<p>Default time to live for job execution result when it is failed.</p> <p>Default: <code>600</code> (10 minutes).</p>"},{"location":"configuration/#scheduler_config-default_job_ttl","title":"SCHEDULER_CONFIG: <code>DEFAULT_JOB_TTL</code>","text":"<p>Default timeout for job info.</p> <p>Default: <code>300</code> (5 minutes).</p>"},{"location":"configuration/#scheduler_config-default_job_timeout","title":"SCHEDULER_CONFIG: <code>DEFAULT_JOB_TIMEOUT</code>","text":"<p>timeout (seconds) for a job.</p> <p>Default: <code>300</code> (5 minutes).</p>"},{"location":"configuration/#scheduler_config-default_worker_ttl","title":"SCHEDULER_CONFIG: <code>DEFAULT_WORKER_TTL</code>","text":"<p>Time To Live (TTL) in seconds to keep worker information after last heartbeat. Default: <code>600</code> (10 minutes).</p>"},{"location":"configuration/#scheduler_config-default_maintenance_task_interval","title":"SCHEDULER_CONFIG: <code>DEFAULT_MAINTENANCE_TASK_INTERVAL</code>","text":"<p>The interval to run worker maintenance tasks in seconds. Default: <code>600</code> 10 minutes.</p>"},{"location":"configuration/#scheduler_config-default_job_monitoring_interval","title":"SCHEDULER_CONFIG: <code>DEFAULT_JOB_MONITORING_INTERVAL</code>","text":"<p>The interval to monitor jobs in seconds.</p>"},{"location":"configuration/#scheduler_config-scheduler_fallback_period_secs","title":"SCHEDULER_CONFIG: <code>SCHEDULER_FALLBACK_PERIOD_SECS</code>","text":"<p>Period (secs) to wait before requiring to reacquire locks.</p>"},{"location":"configuration/#scheduler_config-token_validation_method","title":"SCHEDULER_CONFIG: <code>TOKEN_VALIDATION_METHOD</code>","text":"<p>Method to validate request <code>Authorization</code> header with. Enables checking stats using API token.</p> <p>Default: no tokens allowed.</p>"},{"location":"configuration/#scheduler_queues","title":"<code>SCHEDULER_QUEUES</code>","text":"<p>You can configure the queues to work with. That way you can have different workers listening to different queues.</p> <p>Different queues can use different redis servers/connections.</p>"},{"location":"drt-model/","title":"Worker related flows","text":"<p>Running <code>python manage.py scheduler_worker --name 'X' --queues high default low</code></p>"},{"location":"drt-model/#register-new-worker-for-queues","title":"Register new worker for queues","text":"<pre><code>sequenceDiagram\n    autonumber\n\n        participant worker as WorkerProcess\n\n        participant qlist as QueueHash&lt;br/&gt;name -&gt; key \n        participant wlist as WorkerList\n        participant wkey as WorkerKey\n        participant queue as QueueKey\n        participant job as JobHash\n\n\n    note over worker,qlist: Checking sanity\n\n    break when a queue-name in the args is not in queue-list\n        worker -&gt;&gt;+ qlist: Query queue names\n        qlist --&gt;&gt;- worker: All queue names\n        worker -&gt;&gt; worker: check that queue names exists in the system\n    end\n\n    note over worker,wkey: register\n    worker -&gt;&gt; wkey: Create workerKey with all info (new id, queues, status)\n    worker -&gt;&gt; wlist: Add new worker to list, last heartbeat set to now()</code></pre>"},{"location":"drt-model/#work-execute-jobs-on-queues","title":"Work (execute jobs on queues)","text":"<pre><code>sequenceDiagram\n    autonumber\n\n        participant worker as WorkerProcess\n\n        participant qlist as QueueHash&lt;br/&gt;name -&gt; key \n        participant wlist as WorkerList\n        participant wkey as WorkerKey\n        participant queue as QueueKey\n        participant job as JobHash\n\n    loop Until death\n        worker -&gt;&gt; wlist: Update last heartbeat\n        note over worker,job: Find next job\n\n        loop over queueKeys until job to run is found or all queues are empty\n            worker -&gt;&gt;+ queue: get next job name and remove it or None (zrange+zpop)\n            queue --&gt;&gt;- worker: job name / nothing\n        end\n\n        note over worker,job: Execute job or sleep\n        critical [job is found]\n            worker -&gt;&gt; wkey: Update worker status to busy\n            worker -&gt;&gt;+ job: query job data\n            job --&gt;&gt;- worker: job data\n\n            worker -&gt;&gt; job: update job status to running\n            worker -&gt;&gt; worker: execute job\n            worker -&gt;&gt; job: update job status to done/failed\n            worker -&gt;&gt; wkey: Update worker status to idle\n        option No job pending\n            worker -&gt;&gt; worker: sleep    \n        end  \n    end</code></pre>"},{"location":"drt-model/#scheduler-flows","title":"Scheduler flows","text":""},{"location":"installation/","title":"Installation","text":"<ol> <li> <p>Use pip to install:    <pre><code>pip install django-tasks-scheduler\n</code></pre></p> </li> <li> <p>In <code>settings.py</code>, add <code>scheduler</code> to  <code>INSTALLED_APPS</code>:    <pre><code>INSTALLED_APPS = [\n    # ...    \n    'scheduler',\n    # ...\n]\n</code></pre></p> </li> <li> <p>Configure your queues.    Add at least one Redis Queue to your <code>settings.py</code>.    Note that the usage of <code>QueueConfiguration</code> is optional, you can use a simple dictionary, but <code>QueueConfiguration</code>    helps preventing configuration errors.    <pre><code> import os\n from typing import Dict\n from scheduler.types import QueueConfiguration\n\n SCHEDULER_QUEUES: Dict[str, QueueConfiguration] = {\n  'default': QueueConfiguration(\n     HOST='localhost',\n     PORT=6379,\n     USERNAME='some-user',\n     PASSWORD='some-password',\n     CONNECTION_KWARGS={  # Eventual additional Broker connection arguments\n         'ssl_cert_reqs': 'required',\n         'ssl': True,\n     },\n ),\n 'with-sentinel': QueueConfiguration(\n      SENTINELS= [('localhost', 26736), ('localhost', 26737)],\n      MASTER_NAME= 'redismaster',\n      DB= 0,\n      USERNAME= 'redis-user',\n      PASSWORD= 'secret',\n      CONNECTION_KWARGS= {\n      'ssl': True},\n      SENTINEL_KWARGS= {\n      'username': 'sentinel-user',\n      'password': 'secret',\n   }),\n  'high': QueueConfiguration(URL=os.getenv('REDISTOGO_URL', 'redis://localhost:6379/0')),\n  'low': QueueConfiguration(HOST='localhost', PORT=6379, DB=0, ASYNC=False), \n }\n</code></pre></p> </li> <li> <p>Optional: Configure default values for queuing jobs from code:    <pre><code>from scheduler.types import SchedulerConfiguration, Broker\n\nSCHEDULER_CONFIG = SchedulerConfiguration(\n EXECUTIONS_IN_PAGE=20,\n SCHEDULER_INTERVAL=10,\n BROKER=Broker.REDIS,\n CALLBACK_TIMEOUT=60,  # Callback timeout in seconds (success/failure/stopped)\n # Default values, can be overriden per task/job\n DEFAULT_SUCCESS_TTL=10 * 60,  # Time To Live (TTL) in seconds to keep successful job results\n DEFAULT_FAILURE_TTL=365 * 24 * 60 * 60,  # Time To Live (TTL) in seconds to keep job failure information\n DEFAULT_JOB_TTL=10 * 60,  # Time To Live (TTL) in seconds to keep job information\n DEFAULT_JOB_TIMEOUT=5 * 60,  # timeout (seconds) for a job\n # General configuration values\n DEFAULT_WORKER_TTL=10 * 60,  # Time To Live (TTL) in seconds to keep worker information after last heartbeat\n DEFAULT_MAINTENANCE_TASK_INTERVAL=10 * 60,  # The interval to run maintenance tasks in seconds. 10 minutes.\n DEFAULT_JOB_MONITORING_INTERVAL=30,  # The interval to monitor jobs in seconds.\n SCHEDULER_FALLBACK_PERIOD_SECS=120,  # Period (secs) to wait before requiring to reacquire locks\n)\n</code></pre></p> </li> <li> <p>Add <code>scheduler.urls</code> to your django application <code>urls.py</code>:    <pre><code>from django.urls import path, include\n\nurlpatterns = [\n    # ...\n    path('scheduler/', include('scheduler.urls')),\n]\n</code></pre></p> </li> <li> <p>Run migrations to generate django models    <pre><code>python manage.py migrate\n</code></pre></p> </li> </ol>"},{"location":"migrate_to_v3/","title":"Migration from v2 to v3","text":"<p>Version 3.0.0 introduced a major design change. Instead of three separate models, there is one new <code>Task</code> model. The goal is to have one centralized admin view for all your scheduled tasks, regardless of the scheduling type.</p> <p>You need to migrate the scheduled tasks using the old models (<code>ScheduledTask</code>, <code>RepeatableTask</code>, <code>CronTask</code>) to the new model. It can be done using the export/import commands provided.</p> <p>After upgrading to django-tasks-scheduler v3.0.0, you will notice you are not able to create new scheduled tasks in the old models, that is intentional. In the next version of django-tasks-scheduler (v3.1), the old models will be deleted, so make sure you migrate your old models.</p> <p>Note</p> <p>While we tested different scenarios heavily and left the code for old tasks, we could not account for all different use cases, therefore, please open an issue if you encounter any.</p> <p>There are two ways to migrate your existing scheduled tasks:</p>"},{"location":"migrate_to_v3/#using-the-admin-views-of-the-old-models","title":"Using the admin views of the old models","text":"<p>If you go to the admin view of the old models, you will notice there is a new action in the actions drop down menu for migrating the selected tasks. Use it, and you will also have a link to the new task to compare the migration result.</p> <p>Note once you migrate using this method, the old task will be disabled automatically.</p>"},{"location":"migrate_to_v3/#exportimport-management-commands","title":"Export/Import management commands","text":"<p>Run in your project directory:</p> <pre><code>python manage.py export &gt; scheduled_tasks.json\npython manage.py import --filename scheduled_tasks.json\n</code></pre>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#enqueue-jobs-from-code","title":"Enqueue jobs from code","text":"<pre><code>from scheduler import job\n\n\n@job()\ndef long_running_func():\n    pass\n\n\nlong_running_func.delay()  # Enqueue function in \"default\" queue\n</code></pre> <p>Specifying the queue where the job should be queued:</p> <pre><code>@job('high')\ndef long_running_func():\n    pass\n\n\nlong_running_func.delay()  # Enqueue function in \"high\" queue\n</code></pre> <p>You can pass in any arguments that RQ's job decorator accepts:</p> <pre><code>from scheduler import job\n\n\n@job('default', timeout=3600)\ndef long_running_func():\n    pass\n\n\nlong_running_func.delay()  # Enqueue function with a timeout of 3600 seconds.\n</code></pre> <p>You can set in <code>settings.py</code> a default value for <code>DEFAULT_JOB_TTL</code> and <code>DEFAULT_JOB_TIMEOUT</code>.</p> <pre><code># settings.py\nSCHEDULER_CONFIG = SchedulerConfiguration(\n    DEFAULT_SUCCESS_TTL=10 * 60,  # Time To Live (TTL) in seconds to keep successful job results\n    DEFAULT_FAILURE_TTL=365 * 24 * 60 * 60,  # Time To Live (TTL) in seconds to keep job failure information\n    DEFAULT_JOB_TTL=10 * 60,  # Time To Live (TTL) in seconds to keep job information\n    DEFAULT_JOB_TIMEOUT=5 * 60,  # timeout (seconds) for a job\n)\n</code></pre>"},{"location":"usage/#managing-tasks-through-the-django-admin","title":"Managing tasks through the Django Admin","text":""},{"location":"usage/#viewing-list-of-scheduled-tasks","title":"Viewing list of scheduled tasks","text":""},{"location":"usage/#viewing-details-of-a-scheduled-task","title":"Viewing details of a scheduled task","text":"<p>It is possible to view list of executions of a task, as well as the details of a specific execution. </p>"},{"location":"usage/#scheduling-a-task-through-django-admin","title":"Scheduling a task Through django-admin","text":"<ul> <li>Sign in to the Django Admin site (e.g., http://localhost:8000/admin/) and locate the <code>Tasks Scheduler</code> section.</li> <li>Click on the Add  on <code>Tasks</code></li> <li>Enter a unique name for the task in the Name field.</li> <li>Select the task type, and according to the type, the form will change for the scheduling details.<ul> <li>For <code>Repeatable task</code><ul> <li>Enter an Interval, and choose the Interval unit. This will calculate the time before the function is called   again.</li> <li>In the Repeat field, enter the number of times the job is to be run. Leaving the field empty, means the job   will be scheduled to run forever.</li> </ul> </li> <li>For <code>Cron task</code><ul> <li>In the Repeat field, enter the number of times the job is to be run. Leaving the field empty, means the job   will be scheduled to run forever.</li> <li>In the cron string field, enter a cron string describing how often the job should run.</li> </ul> </li> </ul> </li> <li>In the Callable field, enter a Python dot notation path to the method that defines the job. For the example   above, that would be <code>myapp.jobs.count</code></li> <li>Choose your Queue.   The queues listed are defined in your app <code>settings.py</code> under <code>SCHEDULER_QUEUES</code>.</li> <li>Enter the time in UTC the job is to be executed in the Scheduled time field.</li> </ul>"},{"location":"usage/#optional-fields","title":"Optional fields:","text":"<ul> <li>Select whether the job should take priority over existing queued jobs when it is queued (jobs waiting to be executed)   by using at front.</li> <li>Timeout specifies the maximum time in seconds the job is allowed to run. blank value means it can run forever.</li> <li>Result TTL (Time to live): The time to live value (in seconds) of the job result.<ul> <li><code>-1</code>: Result never expires, you should delete jobs manually.</li> <li><code>0</code>: Result gets deleted immediately.</li> <li><code>n</code> (where <code>n &gt; 0</code>) : Result expires after n seconds.</li> </ul> </li> </ul> <p>Once you are done, click Save and your job will be persisted to django database.</p>"},{"location":"usage/#support-for-arguments-for-tasks","title":"Support for arguments for tasks","text":"<p>django-tasks-scheduler supports scheduling tasks calling methods with arguments, as well as arguments that should be calculated in runtime.</p> <p></p>"},{"location":"usage/#viewing-queue-statistics","title":"Viewing queue statistics","text":""},{"location":"usage/#viewing-queue-specific-registry-jobs","title":"Viewing queue specific registry jobs","text":""},{"location":"usage/#viewing-workers-list","title":"Viewing workers list","text":""},{"location":"usage/#viewing-worker-details","title":"Viewing worker details","text":""},{"location":"usage/#enqueue-jobs-using-the-command-line","title":"Enqueue jobs using the command line","text":"<p>It is possible to queue a job to be executed from the command line using django management command:</p> <pre><code>python manage.py run_job -q {queue} -t {timeout} -r {result_ttl} {callable} {args}\n</code></pre>"},{"location":"usage/#running-a-worker-to-process-queued-jobs-in-the-background","title":"Running a worker to process queued jobs in the background","text":"<p>Create a worker to execute queued jobs on specific queues using:</p> <pre><code>usage: manage.py scheduler_worker [-h] [--pid PIDFILE] [--name NAME] [--worker-ttl WORKER_TTL] [--fork-job-execution FORK_JOB_EXECUTION] [--sentry-dsn SENTRY_DSN] [--sentry-debug] [--sentry-ca-certs SENTRY_CA_CERTS] [--burst]\n                                  [--max-jobs MAX_JOBS] [--max-idle-time MAX_IDLE_TIME] [--with-scheduler] [--version] [-v {0,1,2,3}] [--settings SETTINGS] [--pythonpath PYTHONPATH] [--traceback] [--no-color] [--force-color]\n                                  [--skip-checks]\n                                  [queues ...]\n</code></pre> <p>More information about the different parameters can be found in the commands documentation.</p>"},{"location":"usage/#running-multiple-workers-as-unixlinux-services-using-systemd","title":"Running multiple workers as unix/linux services using systemd","text":"<p>You can have multiple workers running as system services. To have multiple scheduler workers, edit the <code>/etc/systemd/system/scheduler_worker@.service</code> file, make sure it ends with <code>@.service</code>, the following is example:</p> <pre><code># /etc/systemd/system/scheduler_worker@.service\n[Unit]\nDescription = scheduler_worker daemon\nAfter = network.target\n\n[Service]\nWorkingDirectory = {{ path_to_your_project_folder } }\nExecStart = /home/ubuntu/.virtualenv/{ { your_virtualenv } }/bin/python \\\n            {{ path_to_your_project_folder } }/manage.py \\\n            scheduler_worker high default low\n# Optional \n# {{user to run scheduler_worker as}}\nUser = ubuntu\n# {{group to run scheduler_worker as}}\nGroup = www-data\n# Redirect logs to syslog\nStandardOutput = syslog\nStandardError = syslog\nSyslogIdentifier = scheduler_worker\nEnvironment = OBJC_DISABLE_INITIALIZE_FORK_SAFETY = YES\nEnvironment = LC_ALL = en_US.UTF-8\nEnvironment = LANG = en_US.UTF-8\n\n[Install]\nWantedBy = multi-user.target\n</code></pre> <p>After you are done editing the file, reload the settings and start the new workers:</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl start scheduler_worker@{1..3} \n</code></pre> <p>You can target a specific worker using its number:</p> <pre><code>sudo systemctl stop scheduler_worker@2\n</code></pre>"}]}